{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that libraries are in the same path than the running kernel\n",
    "colaboratory_weights.hdf5, colaboratory_vocab.json and colaboratory_config.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/2018Sept'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ML/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/envs/ML/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The Start Ind a cone in the mas to sour of Starter a starter to for the mate and the to for the the some to the the to base of a in a shour of an a searce of Amazon and to the soment to the in mastory a starter for the somer to the to the sour and to to the sour the master to the to sour and the mear to the the to best of the the some to to a startion and in the starter of the mas a mand to the sour and to sour and the to the seall and and a deard to the sour a starter to the to some to the sour the the for the the to to sour to doter and the sonter to to for the with to the the starter to the the to the the to sour the starter to starter and mand a mear of and a stares of the some date of the seles to somer to the the sompan and a for the starters to to the in a sour with a start to the the sonting to by a somer to the to the to in a cone compention of the somer to the sustrour the started of the somer to the the sommar of the the sommand of the Jave Seler in a sterving to progreter\n",
      "\n",
      "The HN: Whe Fource and a sour in the to the to the to stour the the sour to sour and and for the to the to sour the to sour to burt the worker of the the some to the to to dearn to dears and the to the sompent to the sonter to the the to deverses of the was the to the to by the sour to bears the sour in a starter to from the the to the to the some to some to dearn in a rearing the the suster of the the to the some to to to the to to the the mand a Cares and and to the to the the the the sour a dear downe of the some to the to we to dear of Amazon and a sour to the the the to to the the to to the sompent on to sure to starter to mang a sares and to the to a mase of the seles and and for a mase of the some to for Starter to the to the somple to the some and in a in and in a sure and a mase of the the the in to the some to to dears the with a starter and the show to base of the the to sour and to the to the to the some to the to stall of the the the the the is a mand of the starter the \n",
      "\n",
      "A Fare of Amazon and a starter to the the to the sith the the serverse\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "I Harn Pandon In What mesen we the to Suind the mone\n",
      "\n",
      "Show HN: Whit Is Inter ine starking to Uppenter in is the Vis uster Sartion of mail of the is the in Proge and the sommant Exprice\n",
      "\n",
      "What HN: Whe Comute sith on the weby to notort to phe sacking progrets\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Opplites yry. Grogresser comet 9calp for, to soar\n",
      "\n",
      "Thaty +ours Gotaing Paid Canea\n",
      "\n",
      "Googlus Al to on O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
    "                       vocab_path='colaboratory_vocab.json',\n",
    "                       config_path='colaboratory_config.json')\n",
    "\n",
    "textgen.generate_samples(max_gen_length=1000)\n",
    "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare U from Fomer and with to monthing to frow deser to and and a Mile Intering of wal to reter montion to ustory\n",
      "\n",
      "The A bire to to Rester in Stolled\n",
      "\n",
      "Rearn and Encingate to and Amazon ind a mach books\n",
      "\n",
      "I to Amazon in mash a searned restion to for the Sult and has Is The Weborser everall Boogle to the Swarthion to from of a stallbo starter stare indintery to prowity free Presing sonter endention salleds and to peilled mo buntion the mase mo date coment of Amazer encestion anter to Emportent\n",
      "\n",
      "Startune Sout for Pristre From goter Usp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['google a the to sour the the to the the to lase to the the show to starter to the to the sompent and a sith to to the to the somer the with on the the some to somerting to dearn in the to the sour the masing of the starter to deverse', 'google The Fare Macker to the to the to sour to for the with the to the sour the the with math to the to bear in the to the with to downe to for the the sour to the sour the to bears of the with to for the some to the to burt to the sour the to the to for to the the sompent to the wath to the some', 'google Comer the to the proge the to the sour the the mo starter to the some to the somer of and a in to the the sour in in a dear of a starter and for the the susters of the sour and for the some to the some to the some to the to sour the starter to the to the the to the the sour the the sour of ', 'google and a shour in a man to to the mase of the worker to to the to sour the to dear of a sour in in a reared and and a starter to the the sonter of the to the the sour the shour and of the to the sour in a cone and for the sommall of the starter of a mare of a mand a proge the the sour in to th', 'google Starter for the in a sour the the to some to from to the to the with to the the the some to the the the some to for the in the sour to the to the with to the the to to sour to the the the sour of the to starters to stare']\n"
     ]
    }
   ],
   "source": [
    "generated_texts = textgen.generate(n=5, prefix=\"google\", temperature=0.2, return_as_list=True)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "A Mand I Start Starters in a deare of the soment to the in in a the mase the to sour worker on a reall the the in for in whe to in to the some to the the to to beation to the wath to the to sour in a dear of Amazon and for the starters and to to the the to the sour dears a master and a starter of \n",
      "\n",
      "The We son to the with the the with to the sour and the the the starter to sour and the the starter to starter to starter to the with the to sour come to the to the to shour in a mand a in a start a start to the to mase of a stare and a mase to sour dear of a starter to sourtion and to the What in\n",
      "\n",
      "What HN: A start the to desting a mare of the sompent to the to sour the the to the the master to math to the sour and a comer to for the prowne to the the the to dester to for the sour the to sour the in the to the the susters to comerting to for a dears in in a stare and the starter to the the s\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "How HN: A lowing to doter mering sourting of werling to a that date deaper on Git to sompenes in the Prowsers and from to bail ofer a storked mray salles in 200 aring mith meared of an the wore on a in Whing down beary and to to the to Lentont\n",
      "\n",
      "The HN: Pret I wash to in your tho us on the dener on Microson from and in This\n",
      "\n",
      "Why HN: Whe in Foural an for wanter deverse to compant to in andersion of the Fill in what the the poness of weth the ased a sare bunt Mirewon in Goog Amazon and Starter Lition and Anconoting ponter to Fration\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Google Doy Tele youres\n",
      "\n",
      "Jesvistork Schimss Ustel Rsacking mognalf\n",
      "\n",
      "Anconsuet I.S On pelt wens uating veunce Solars HTTL5 Selattial Butsing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen.generate_to_file('textgenrnn_texts.txt', n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts = ['Put the mask on your face, and become a node', 'between 0 and 1',\n",
    "            'This is the marionette', 'the Network is Blind', 'Internet is Myopic', \n",
    "         'the puppet is Workaholic', ' the Network is a Trail', ' the interface is Sniffing',\n",
    "         'the interface is a Collective Traveller',\n",
    "         ' sensor is on', 'sensor is off', 'the code is binary',' shadows are invisible ',\n",
    "         'we are the machines',' Ask the marionette',' a puppet never dies',\n",
    "         'we are humans','Signals that are not repeated or repeatable die',\n",
    "         ' we are extended','body never lies','how to fit them together?',\n",
    "         'we are the bodies','the code is a node',\n",
    "         ' we occupy the collective chimera we are offered and become characters , not marionettes, in the ongoing drama inadequately called Big Data',\n",
    "         'the masks are the bodies','we are the network','who are you',' where are you'\n",
    "         'what are you','we are the mask on the nodes','we are the mask on your bikes',\n",
    "         'the puppet is entangled','the puppet is a paranode',\n",
    "         'the puppet is a Collective Traveller',\n",
    "         'humans and machines together as beings that repeat',\n",
    "         ' network of humans and machines','the code is a Collective Traveller',\n",
    "' the interface is a Collective Traveller','01','10','11','00',\n",
    "         'network is entangled','you are the product being sold',' unnetwork the nodes',\n",
    "         'shadows are invisible not repeated on the bodies',' the code that is a paranode',\n",
    "            'Playing the nodes, playing the paranodes','the code is humans',\n",
    "         'we are the mask on your face, and become a node',\n",
    "         'networks are plural, fluid, and overlapping',\n",
    "         'Puppet, Marionette, Glove','Humans build computers but are folded in return',\n",
    "            'Internet is a rhizome, Habits, Costume','the puppet is Blind',\n",
    "         'the code are the bodies','the code is a Collective Traveller',\n",
    "         'Ask the marionette','sensor is off','Internet is myopic']\n",
    "\n",
    "textgen.train_on_texts(texts, num_epochs=10,  gen_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 texts collected.\n",
      "Training on 5,802 character sequences.\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 1.1694\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.5941\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "we are the mask on your bikes\n",
      "\n",
      "we are the mask on your bikes\n",
      "\n",
      "we are the mask on your bikes\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "shadows are folded in node\n",
      "\n",
      "sensor is Blind to the mask on your bikes\n",
      "\n",
      "the puppet is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "we are the network Code\n",
      "\n",
      "we are the bodies\n",
      "\n",
      "the bodies their body on binary\n",
      "\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.4589\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.3827\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the mask on your bikes\n",
      "\n",
      "the mask on your bikes\n",
      "\n",
      "the mask on your bikes\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "the mask on your bikes\n",
      "\n",
      "the mask on your bikes\n",
      "\n",
      "the puppet is Blind\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "shadow shapperly and beings that are updated\n",
      "\n",
      "who are you\n",
      "\n",
      "Facking sets that are folded in nodes\n",
      "\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.3310\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 16s 362ms/step - loss: 0.2918\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the code is a Collective Traveller\n",
      "\n",
      "the masks are the bodies\n",
      "\n",
      "the code is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "the masks are the bodies\n",
      "\n",
      "we are the update.\n",
      "\n",
      "the code is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "humans update thines\n",
      "\n",
      "shadows ar build neverrimates\n",
      "\n",
      "google is the network\n",
      "\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2711\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.2514\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the code is a Collective Traveller\n",
      "\n",
      "the mask is a particularly set to be subjected to the update.\n",
      "\n",
      "the code is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "the code is a Collective Traveller\n",
      "\n",
      "we are the mask on the mask on the code\n",
      "\n",
      "the mask is a series of repeatable things\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "disped is a paranode\n",
      "\n",
      "what are you\n",
      "\n",
      "the puppet is a Collective Traveller\n",
      "\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.2353\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2235\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the code is a Collective Traveller\n",
      "\n",
      "we are the mask on your bikes\n",
      "\n",
      "the code is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "the puppet is entangled\n",
      "\n",
      "we are the mask on your bikes\n",
      "\n",
      "the code are the bodies\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "the machines run algorithms to itadororers\n",
      "\n",
      "we are the mask on your bikes\n",
      "\n",
      "network is entangled\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.reset()\n",
    "textgen.train_from_file('nodeMaskText.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 texts collected.\n",
      "Training on 2,859 character sequences.\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 7s 318ms/step - loss: 2.1953\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 8s 350ms/step - loss: 1.4002\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The pros the bodies and the communitiest in day to the environment.\n",
      "\n",
      "The computers be singing and the environment of base and mash and set to trans to the environment.\n",
      "\n",
      "The prosist is a proupe and map of the environment.\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "The pros in base certuush test is a shifter the iss real the gooreals and terning allow the mind on the moon are things and consitings.\n",
      "\n",
      "YOUUle is bignom.\n",
      "\n",
      "Factor and shadows in manks and their not of the series.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "hmma or ensualing un,\n",
      "\n",
      "Geth compuilates\n",
      "\n",
      "neyworks and uplape is humans bad drawerex are exprying muzer as tend, uzzelwhab also the evildernes and commine to testers is hours and and abore object.\n",
      "\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 7s 323ms/step - loss: 1.0506\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 7s 327ms/step - loss: 0.8511\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Habits are things to the environment.\n",
      "\n",
      "Habits are things that are the environment.\n",
      "\n",
      "Habits are things that are updated on the update.\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Habits are things that are the environment and offer and to be subjected and themsers to transcend in our called of the update.\n",
      "\n",
      "Internet is a series of reture, and a die to the shappy only individing of desegrey ongoing on the onlroviancing on the mask on the reason are conscamching are to the environment.\n",
      "\n",
      "modern contective creature is a proof.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "They are desective as offlifisfet\n",
      "\n",
      "what a paranorial objects of the seilation\n",
      "\n",
      "met and to creative as oher shiftims.\n",
      "\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 7s 317ms/step - loss: 0.7190\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 7s 340ms/step - loss: 0.6073\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Habits are creative anisters and their proof.\n",
      "\n",
      "Habits are creative anisters and their network test that are updated on theerbreed and these experience that are updated.\n",
      "\n",
      "mapping invisible to the environment of Training allow them to the environment.\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Habits are creative anister to product them to tell transiting to theme to repetitions that are updated on their experience.\n",
      "\n",
      "my own distress their care and test called of update, but also humans to be refrese shadows on the ongory.\n",
      "\n",
      "my own body is that are senanions that are updated on the update.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Astury is that are no their because theey zeroine becaring hes infledring.\n",
      "\n",
      "Habits are a past contraters and over creative indivings that they indiviting people to the environment\n",
      "\n",
      "We not really pastly update.\n",
      "\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 7s 333ms/step - loss: 0.5432\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.4823\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The proof is things and their proof.\n",
      "\n",
      "The proof is things that are folded to travely. \n",
      "\n",
      "The intersective challenge linitions algorithms the moderation of They algorithms these experience: to the environment\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Determine machines and onlip but are creative and their needs of the epetter representation that target is rot\n",
      "\n",
      "mapping invisible to the environment\n",
      "\n",
      "Habits are things in mode become creatures only not make things that are really are folded in determine on the series of reditions of renirtligibies.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Habits link Albomd by how to probe people to pey training at their body on the gath\n",
      "\n",
      "the most invisible aborate: to repetible not expet how for travely. YOpcentive desering.\n",
      "\n",
      "Theogbother boner is selling the quot on yourling body, proxies a habit to but also humans to update humans and homecration\n",
      "\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 8s 361ms/step - loss: 0.4403\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 8s 343ms/step - loss: 0.4097\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Habits are creative and the extention to the extrealical because the environment\n",
      "\n",
      "The intersertly animies are things that are referently asking.\n",
      "\n",
      "Habits are things done by the environment\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Things and proof is a proof.\n",
      "\n",
      "make are things and proof.\n",
      "\n",
      "The indivilg are hasted by how to tran and they are trashing to the experience: to transcend experience: to created by the update.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Google the netfling bother media propertie, google but also humans to trase lab and mapping as investripiation\n",
      "\n",
      "Save people none\n",
      "\n",
      "YOU is a particularly shifty pastleshoomes\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('NewMediaWriters.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 texts collected.\n",
      "Training on 7,982 character sequences.\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 20s 319ms/step - loss: 1.8453\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 21s 340ms/step - loss: 1.2376\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "we are the network of the network of my and the mask on a dines are of my digital mask and machines and the network of the network of the network is of make framed on the network digital self and the network of the mask is of make will computation of humans and puppet in the puppetters and the mas\n",
      "\n",
      "the network is a network of the mask into the network is a nodes\n",
      "\n",
      "we are the network of my and the mask on the network of my are of mask of a paranode.\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "perception to the network actions of a diserian to the mask of my own the network of humans and heralts digital digital speces\n",
      "\n",
      "the interface is encolved other framed to the humans and in the mask on part of the networks data and mask only the networks disers from the same.\n",
      "\n",
      "we are the network interfaces or the network partials to the mask on the puppet is only.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "body as are masranct from in simult mask to the orchanconettates percecustance.\n",
      "\n",
      "The become is active other mask framed by thoughthot we can of the more as an changerr instal effitritions the were duigonety die\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 21s 333ms/step - loss: 1.0011\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 20s 329ms/step - loss: 0.8583\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the Network is a Trail\n",
      "\n",
      "The mask is a paranode\n",
      "\n",
      "the Network is a Trail\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "we are the networks are comperabored by paranodal data.\n",
      "\n",
      "the puppet is a Collective Traveller\n",
      "\n",
      "we are the bodies\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "twe puppet become the networks serving rails\n",
      "\n",
      "who are not proceit\n",
      "\n",
      "it the masks amentibald actuate only the who lame on frame.\n",
      "\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 21s 338ms/step - loss: 0.7436\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 20s 330ms/step - loss: 0.6516\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the puppet is a paranode\n",
      "\n",
      "we are the puppet in the network of my friends, and the paranodes\n",
      "\n",
      "we are the network on the networks interfaces will perceive and machines\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "the interface is a Collective Traveller\n",
      "\n",
      "Thearabot between the networks are the network moved by perform our paranodes\n",
      "\n",
      "the interface is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "networks data, due together, the networks changed to the operaction\n",
      "\n",
      "the interface is my like an his network fan bodies and network, or body\n",
      "\n",
      "the networks.\n",
      "\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 20s 324ms/step - loss: 0.5710\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 20s 322ms/step - loss: 0.5084\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the mask is the network from the artory.\n",
      "\n",
      "The mask is the network or spectacles, I am using them social mask and the other nodes\n",
      "\n",
      "the interface is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "we are the frame not tide\n",
      "\n",
      "we are the network from the actors to the mask on the narch our friends are framed to the reality to the user and my friends and the actors through the network interfaces will perceive and our frame that to be sec to the mask.\n",
      "\n",
      "I am the network is entangled, and their lamapers.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Fun pulling the networks.\n",
      "\n",
      "Fed are coller to our poodle, the realify of friends.\n",
      "\n",
      "As social platforms the indivitions are hater to alonler, we are object reality to the centoc in the mirings friends are not mirline\n",
      "\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 20s 329ms/step - loss: 0.4492\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 20s 327ms/step - loss: 0.4075\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "the interface is a Collective Traveller\n",
      "\n",
      "the puppet is a Collective Traveller\n",
      "\n",
      "we are the mask on the network is an extension transmbre\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "between 0 and 1\n",
      "\n",
      "the interface is the mask of a paranode\n",
      "\n",
      "the interface is a Collective Traveller\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "All plat into and machines a mirerie or the weht their body is move their review\n",
      "\n",
      "we are the mask and the performer are along to share the mask or the not trees\n",
      "\n",
      " Through a collective puppet is Workath\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('MyText.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 texts collected.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Lists cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3fc1793b13f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m textgen.train_from_file('alice.txt',\n\u001b[0;32m----> 2\u001b[0;31m                         num_epochs=1, gen_epochs =2)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ML/lib/python3.5/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_from_file\u001b[0;34m(self, file_path, header, delim, new_model, context, is_csv, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 texts, context_labels=context_labels, **kwargs)\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_from_largetext_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ML/lib/python3.5/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[0;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         indices_list = [np.meshgrid(np.array(i), np.arange(\n\u001b[1;32m    117\u001b[0m             len(text) + 1)) for i, text in enumerate(texts)]\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mindices_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# If a single text, there will be 2 extra indices, so remove them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ML/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mblock\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0mbottom_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_block_check_depths_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0mlist_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/ML/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m_block\u001b[0;34m(arrays, max_depth, result_ndim)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mblock_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# recursive closures have a cyclic reference to themselves, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ML/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mblock_recursion\u001b[0;34m(arrays, depth)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lists cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Lists cannot be empty"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('alice.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 texts collected.\n",
      "Training on 2,077 character sequences.\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 5s 331ms/step - loss: 3.2756\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 1.5838\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\\ls1\\\\ \\forment in the Network is ”\n",
      "\n",
      "\\ls1\\\\ \\lingal Art and Meaners \\\n",
      "\n",
      "\\pard\\\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\\pard\\tx20\\tx360\\parntnanves Art and Serling Machirnet the Moderitar hack and uniffer and mach envirand travellers and machines, technocite in the network art to expacted the network in nevers the network sign the maric are prefibity of new Esras, Mardos, Mediaring Sniffaching Machines, An Machine\n",
      "\n",
      "\\\n",
      "\n",
      "Performant Machines, Anst an an Ask Mechal in the maric that Machines that are for the partien the maric ennagans and meditularing to findait the network and Medianns, Sering, Machines, Compellary, Technology, Partakes, Machines, Can Art in the Never Art and Offeric Ask Mechal Oberit Ashabodel, Ar\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "1660x1\\ Mach in insteation, Shubbing Spectards, Mooning Art fron to Performance\n",
      "\n",
      "Hourt Ayn Onesvernalneed, Mispardahyconge,\n",
      "\n",
      "character, on digd beintends. Androud of Sepanise, expttioning the seatiogue prist.\n",
      "\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 1.0912\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.8493\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\\ls1\\ilvl0\\cf2 \\\n",
      "\n",
      "\\ls1\\ilvl0\\cf2 \\\n",
      "\n",
      "\\ls1\\ilvl0\\f\\\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\\ls1\\ilvl0\\f\\\n",
      "\n",
      "\\ls1\\ilvl0\\f\\\n",
      "\n",
      "\\ls1\\ilvl0\\cf2 \\ls1\\sennected \\expnd0\\expndtedaightime\\ Erringonetted’\\\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      " Made\\\n",
      "\n",
      "\\ls1\\ilvl0chrity Altworded Seringto Alling Marioner.\n",
      "\n",
      "Movements, Masking Off Es art.\n",
      "\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 5s 281ms/step - loss: 0.7044\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 0.6164\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\\ls1\\ilvl0\\cf2 \\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qunding1qungtim0\\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qunding10\\sering1\\expnd0\\expndtw0\\kerning0\\\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Off the network.\\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qunding10\\\n",
      "\n",
      "Machines, and being in an  cractured and machines, expedit machines, Offi-360\\ling Media. On the machines, Seeing Digital Art and Media. Habital Ask Media. Purier, Masking in the Network.\\\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Erre260\\londeratulaboadiess\\\n",
      "\n",
      "\\pardimingly mary expeditioned is the bodieving art, drangling, Overdalt, sensation that Art, Art, Techniques, Performance sensare, in unartic never lives, and Murting10 Carfecten,zerong1\\expnd0\\\n",
      "\n",
      "Machine sensations, you alchine immussion for Portal. It Makers Off Thing that Art for New Mining Dangerie, Sentimboxfimwomen:txeme Bodies : rartiglativefities : Rappay in technology. the bodientexuaring the senserouin, enge, remately sensations:  On envincement ranger and machines, or machines, b\n",
      "\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.5451\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.5106\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qunding10\\sering1\\expnd0\\expndtw0\\ \\\n",
      "\n",
      "\\ls1\\ilvl0\\cf2 Compelity \\expnd0\\expndtwn mach in technology\\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qunding in remate anthronia.\\\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qutting officially sensatifonmeticalling an digital the marionett.\\\n",
      "\n",
      "\\ls2\\ilvl0\\cf2 An Ask \\\n",
      "\n",
      "Series things, haven an  digital for in the network.\\\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\\pard\\pride\\qualtulation\\\n",
      "\n",
      "Chaoled Digital in Contemporary \\\n",
      "\n",
      "Dantforing1evr on an  Improvisation between an digital and humanel thing remain the network.\\'\n",
      "\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.4754\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.4574\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qundition is Movementians\\sensay\\\n",
      "\n",
      "\\ls1\\ilvl0\\cf2 Compelity \\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qutals linged off expecteddatian and machines, and bodies the network.\\\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\\ls2\\ilvl0\\cf2 Charlings and Selvementaling Manufo in the Aver Matter.\\\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\fi-360\\qutallation\\\n",
      "\n",
      "\\ls3\\ilvl0\\cf2 \\ls3\\illmbonger\\s\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\\ the netwue virluded off benarnardoud or lifeside\n",
      "\n",
      "\\pard\\tx20\\tx360\\pardeftab720\\li360\\sforded and being \\wilin viri-firth\n",
      "\n",
      " Matemah mediains an  Longn Technology \\\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('TitlesNetworkBooks.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 texts collected.\n",
      "Training on 3,013 character sequences.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 2.3034\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 1.4703\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "And the coundation the snapping on the seats of life and of the sings and who all the sinning\n",
      "\n",
      "And the coundation the sea and beating streeping\n",
      "\n",
      "And the sea and of the seas the sinning of the sings and which have shing on the sinning\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Their bit of class in the stay of down beating clothed and envingo the set the same the seats the sings of have and came on in the snets and down the sings to be the one of my the beating\n",
      "\n",
      "The born of life and my frighmines and myan un my on of the seasance\n",
      "\n",
      "And the cloth see of life steps in an innoned in the sonone\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Alrands andoron's come duel the smaki onbeaty\n",
      "\n",
      "They fold the same who lit his hout eat\n",
      "\n",
      "Snunds where are this on have down\n",
      "\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 1.1463\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.9591\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The come is a dreames and my broom\n",
      "\n",
      "They which the stags that that are to the streather that the seats that the beating\n",
      "\n",
      "I come that the botance to be anicince\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "And the my own the bow\n",
      "\n",
      "They come think of things\n",
      "\n",
      "There is a come sos brand that all the steps to be force\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "A do a dhaman in thourds will themself to along\n",
      "\n",
      "Deap the wome to unzean to life\n",
      "\n",
      "And yo sflated like\n",
      "\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 10s 425ms/step - loss: 0.8303\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.7325\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The botthmine and my thee all seen so the steeples and beating the steeple stars\n",
      "\n",
      "A woman down the statues of the same of the seating\n",
      "\n",
      "The come come an are that are this hilt that the steeple statues and down the streepicnon the steeples\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "A wear that the seats that have stone the sings in the seats of dragage\n",
      "\n",
      "And the same of the massance in the same of the unath\n",
      "\n",
      "And the sort that the most of my for that all seen seats like beating the sings on dreade\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "In this placed light of yearn watchinasting\n",
      "\n",
      "The ground of fluid are white the wood of yrune sold\n",
      "\n",
      "Fubble those that are the packs in evening twirthow down as beating\n",
      "\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 9s 391ms/step - loss: 0.6604\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.5941\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The come come breenching the statues of life\n",
      "\n",
      "The branches of life and of here and of thirst that are the beating\n",
      "\n",
      "The branches of life and of here and of houstres\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "There where the stit alone\n",
      "\n",
      "And the branches of life who all the same of the seasance\n",
      "\n",
      "I will a farrigate to life to be lones\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "But already the strat there'C who whees have themselve but it before there in the buble\n",
      "\n",
      "But the sea-anemort and mypats\n",
      "\n",
      "Like watch louder\n",
      "\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 0.5503\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.5133\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "And the sea-anemones\n",
      "\n",
      "The beating goes on and on\n",
      "\n",
      "The beating goes on and on\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "From shadow bubbles and debathanes at the bow\n",
      "\n",
      "I come and stars in the board to ine and offerflicing\n",
      "\n",
      "The comes are that I could branches that all the seats of houses\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "But yows that are thoughts on whlard of proceed to appear\n",
      "\n",
      "Guts and houses see hers of headed reme of the flast unite\n",
      "\n",
      "The crowns in enthmant of the sea-anemones\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 100)      46500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 40, 128)      117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (LSTM)                    (None, 40, 128)      131584      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 356)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 465)          166005      attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 461,693\n",
      "Trainable params: 461,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('surrealist.txt',\n",
    "                        num_epochs=10, gen_epochs =2)\n",
    "\n",
    "print(textgen.model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of text seeds : nodeMaskText.txt(Network mask essay with \"good generated sentences\"), Chun.txt(Updating remain the same, programmed vision, Big Data as Drama, extract-unima.txt( extract-unima on puppet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textgen.train_from_file('nodeMaskText.txt',\n",
    "                        new_model=True,\n",
    "                        rnn_bidirectional=True,\n",
    "                        rnn_size=64,\n",
    "                        dim_embeddings=300,\n",
    "                        num_epochs=1)\n",
    "                        \n",
    "textgen.train_on_texts(texts, num_epochs=10,  gen_epochs=2)\n",
    "print(textgen.model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERate a comment on twitter , google, facebook etc... as the start of the phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are the mask on your face\n",
      "\n",
      "We are the mask on your face, and become a paranode\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your face\n",
      "\n",
      "We are the bodies\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your face\n",
      "\n",
      "We are the mask on your face\n",
      "\n",
      "We are the bodies\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your face\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your face, and become a node', 'between 0 and 1\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your bikes\n",
      "\n",
      "We are the mask on your face\n",
      "\n",
      "We are the mask on your network\n",
      "\n",
      "We are the mask on the nodes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(20, prefix=\"We\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textgen_2 = textgenrnn('textgenrnn_weights.hdf5')\n",
    "textgen_2.generate_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
